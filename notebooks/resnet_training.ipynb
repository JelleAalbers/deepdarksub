{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from multihist import Hist1d, Histdd\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "import deepdarksub as dds\n",
    "\n",
    "import lenstronomy as ls\n",
    "import manada\n",
    "import fastai.vision.all as fv\n",
    "import torch\n",
    "\n",
    "data_dir = dds.MANADA_ROOT.parent / 'datasets' / 'd_los_sigma_sub'\n",
    "\n",
    "ls.laconic()\n",
    "meta, galaxy_indices = dds.load_metadata(data_dir, remove_bad=False)\n",
    "manada_config = dds.load_manada_config()\n",
    "\n",
    "result_dir = Path('.') / 'train_results'\n",
    "result_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()), torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-decrease",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty = 'diagonal'\n",
    "\n",
    "mp = 'main_deflector_parameters_'\n",
    "fit_parameters = {\n",
    "    mp + 'theta_E': \"Einstein radius [arcsec]\",\n",
    "    'subhalo_parameters_sigma_sub': r'$\\Sigma_\\mathrm{sub}$',\n",
    "    #'los_parameters_delta_los': r'$\\delta_\\mathrm{LOS}$',\n",
    "  \n",
    "# Make sure to turn off rotation augmentation when fitting these\n",
    "# (or reformulate them in rotation-invariant variables, or find out how to \n",
    "# transform y values in fastai)\n",
    "#     mp + 'center_x': \"Main deflector $x$\",\n",
    "#     mp + 'center_y': \"Main deflector $y$\",\n",
    "#     mp + 'gamma': \"Main deflector $\\gamma$\",\n",
    "#     mp + 'gamma1': \"Main deflector $\\gamma_1$\",\n",
    "#     mp + 'gamma2': \"Main deflector $\\gamma_2$\",\n",
    "#     mp + 'e1': \"Main deflector $e_1$\",\n",
    "#     mp + 'e2': \"Main deflector $e_2$\",\n",
    "#     'source_scaled_flux_radius': \"Source flux radius [arcsec]\",\n",
    "#     'source_parameters_sersicfit_n': \"Source best-fit Sersic index\",\n",
    "#     'source_parameters_sersicfit_q': \"Source best-fit Sersic axis ratio\",\n",
    "}\n",
    "\n",
    "n_params = len(fit_parameters)\n",
    "\n",
    "debiased = False\n",
    "with open('debiasing_weights.pkl', mode='rb') as f:\n",
    "    meta['training_weight'] = pickle.load(f)\n",
    "    debiased = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = dds.data_block(\n",
    "    meta, fit_parameters,\n",
    "    data_dir,\n",
    "    uncertainty=uncertainty,\n",
    "    augment_rotation='free',\n",
    ")\n",
    "# Datablock debugging\n",
    "#dblock.summary(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256  # 512\n",
    "dls = dblock.dataloaders(None, bs=batch_size)\n",
    "dls.valid.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Note the pixel value distribution is very skewed:\n",
    "# bla = dls.train.one_batch()[0].cpu().numpy()\n",
    "# Hist1d(bla[:,0,:,:].ravel(), bins=400).plot()\n",
    "# #plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-following",
   "metadata": {},
   "source": [
    "Some source images still have a large mean value. Should we subtract that so zero-padding makes sense? Or is something else going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image\n",
    "# img = dls.valid.one_batch()[0][0].cpu().numpy()\n",
    "# import deepdarksub as dds\n",
    "# dds.plot_image(img[0], vmin=1e-6)return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check train & val shapes match\n",
    "# dls.train.one_batch()[0][0].shape, dls.valid.one_batch()[0][0].shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "architecture = fv.xresnet18\n",
    "pretrained = False\n",
    "freeze_epochs = 2 if len(meta) < 20_000 else 1   # Only relevant from pretrained\n",
    "\n",
    "result_name = '_'.join([architecture.__name__, '%04d' % n_epochs, data_dir.stem])\n",
    "if not pretrained:\n",
    "    result_name += '_fromscratch'\n",
    "if debiased:\n",
    "    result_name += '_debiased'\n",
    "\n",
    "if 'subhalo_parameters_sigma_sub' in fit_parameters:\n",
    "    _sigma_sub_i = list(fit_parameters).index('subhalo_parameters_sigma_sub')\n",
    "    def rho_sub(x, y):\n",
    "        return stats.pearsonr(x[:, _sigma_sub_i],  y[:, _sigma_sub_i])[0]\n",
    "\n",
    "learn = fv.cnn_learner(\n",
    "    dls, architecture,\n",
    "    n_in=1,\n",
    "    n_out=dds.n_out(n_params, uncertainty),\n",
    "    loss_func=dds.loss_for(n_params, uncertainty),\n",
    "    metrics=[fv.AccumMetric(rho_sub, to_np=True, flatten=False)],\n",
    "    pretrained=pretrained)\n",
    "#learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save a learner for use outside this notebook,\n",
    "# first recreate the learner without metrics,\n",
    "# then skip training and instead do:\n",
    "# learn = learn.load(result_name)\n",
    "# learn.export(result_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-arthritis",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pretrained:\n",
    "    base_lr = 0.002 * batch_size / 64\n",
    "    # base_lr = 0.002  # default for fine_tune\n",
    "    learn.fine_tune(n_epochs, base_lr=base_lr, freeze_epochs=freeze_epochs)\n",
    "else:\n",
    "    #base_lr = 1e-4  # From-scratch densenet needs lower LR\n",
    "    # https://github.com/fastai/fastai/blob/75f4c17dc019aee9a0af08bd458a56e00d7393f8/fastai/learner.py#L18\n",
    "    base_lr = 0.001 * batch_size / 64\n",
    "    learn.fit_one_cycle(n_epochs, lr_max=base_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-boring",
   "metadata": {},
   "source": [
    "0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-calculator",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dict()\n",
    "out.update(**dict(zip(\n",
    "    ['train_loss', 'val_loss', 'rho_sub'], \n",
    "    np.stack(learn.recorder.values).T.tolist())))\n",
    "out['train_loss_hr'] = [x.numpy().item() for x in learn.recorder.losses]\n",
    "out['epoch_duration'] = learn.recorder.log[-1]   # only last epoch... oh well\n",
    "out['architecture'] = architecture.__name__\n",
    "out['freeze_epochs'] = freeze_epochs\n",
    "out['base_lr'] = base_lr\n",
    "out['batch_size'] = batch_size\n",
    "out['pretrained'] = pretrained\n",
    "out['fit_parameters'] = fit_parameters\n",
    "out['uncertainty'] = uncertainty\n",
    "out['n_images'] = len(meta)\n",
    "out['n_epochs'] = n_epochs\n",
    "\n",
    "with open(result_dir / (result_name + '.json'), mode='w') as f:\n",
    "    json.dump(out, f)\n",
    "\n",
    "learn.save(result_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-engineer",
   "metadata": {},
   "source": [
    "## Quick Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = dds.Normalizer(meta, fit_parameters)\n",
    "\n",
    "preds, targets = learn.get_preds(reorder=False)\n",
    "y_pred, y_unc = normalizer.decode(preds, uncertainty=uncertainty, as_dict=True)\n",
    "y_true = {p: meta[meta['is_val']][p].values \n",
    "          for p in fit_parameters}\n",
    "#y_true, _ = normalizer.decode(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(\n",
    "#     #y_pred['main_deflector_parameters_theta_E'],\n",
    "#     meta[meta['is_val']]['main_deflector_parameters_theta_E'],\n",
    "#     #meta[meta['is_val']]['subhalo_parameters_sigma_sub'],\n",
    "#     y_pred['subhalo_parameters_sigma_sub'],\n",
    "#     s=5, marker='.', edgecolors='none', c='k'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# err, corr = zip(*[cov_to_std(q) for q in y_cov])\n",
    "# err, corr = np.stack(err), np.stack(corr)\n",
    "# y_unc = {p: err[:,i] for i, p in enumerate(fit_parameters)}\n",
    "# Hist1d(corr[:,0,1], bins=100).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 3 # int(np.ceil(n_params**0.5))\n",
    "n_cols = int(np.ceil(n_params/n_rows))\n",
    "fsize = 3.5\n",
    "f, axes = plt.subplots(n_rows, n_cols, \n",
    "                       figsize=(n_cols * fsize, n_rows * fsize))\n",
    "axes_flat = axes.ravel()\n",
    "\n",
    "for i, (p, label) in enumerate(fit_parameters.items()):\n",
    "    \n",
    "    r, p_r = stats.pearsonr(y_pred[p], y_true[p])\n",
    "    rmse = np.mean((y_pred[p] - y_true[p])**2)**0.5\n",
    "    \n",
    "    ax = axes_flat[i]\n",
    "    plt.sca(ax)\n",
    "    plt.scatter(y_true[p], y_pred[p], \n",
    "                c=y_unc[p] if uncertainty == 'diagonal' else 'b',\n",
    "                s=1, marker='.', #edgecolors='none',\n",
    "                #alpha=0.1,\n",
    "                cmap=plt.cm.Blues_r\n",
    "               )\n",
    "    ax.set_aspect('equal')\n",
    "    xlim, ylim = plt.xlim(), plt.ylim()\n",
    "    mi, ma = min(xlim[0], ylim[0]), max(xlim[1], ylim[1])\n",
    "    plt.plot([mi, ma], [mi, ma], color='k', linewidth=1, alpha=0.5)\n",
    "    #plt.axhline(np.median(y_true[p]), color='k', linewidth=1, alpha=0.5, linestyle='--')\n",
    "    plt.xlim(*xlim), plt.ylim(*ylim)\n",
    "    # plt.colorbar(label='Uncertainty')\n",
    "    # plt.title(p)\n",
    "    plt.xlabel(label, fontsize=14)\n",
    "    \n",
    "    plt.text(0.5, 1.1, \n",
    "             fr\"$\\rho={r:.03f} \\;\\; \" + \n",
    "                 (fr\" (p={p_r:.02f})$\" \n",
    "                  if p_r > 0.005 \n",
    "                  else fr\"\\mathrm{{RMSE}}={rmse:.3f}$\"),\n",
    "             ha='center',\n",
    "             transform=ax.transAxes)\n",
    "    \n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "for ax in axes_flat[i + 1:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.savefig(result_dir / (result_name + '.png'), dpi=200, bbox_inches='tight')\n",
    "#plt.savefig('10minutes_many_parameters.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
